---
title: "R Notebook"
output: html_notebook
---


### Step1: Processing the data

```{r}

training <- readRDS("../output/training.RData")
testing <- readRDS("../output/testing.RData")

training_y <- training[ , "y"]
dim(training_x)
training_x <- training[ ,!(colnames(training) %in% c("y"))]
testing_y <- testing[ ,"y"]
testing_x <- testing[ , !(colnames(testing) %in% c("y"))]

```


### Step2: Train and Test Function

```{r}

train<- function(dat, label,N){
  
  library(randomForest)
  
  t = proc.time()
  df <- as.data.frame(cbind(dat, label))
  colnames(df)[ncol(df)]<-"y"
  fit <- randomForest(as.factor(y)~.,data = df, importance = TRUE,ntree = N)
  
  train_time = (proc.time() - t)[3]
  cat("Elapsed time for Training Random Forest with 500 trees is ", train_time, " seconds \n")
  
  return(fit)
}


test<- function(model, dat){
  
  pred <-predict(model,newdata=dat)
 
  return (pred)
}

```


### Step3: Chooce the best parameter

```{r}
error_testing<-c()
N<-c(300,400,500,600,700,800,900)

for(i in 1:7){

  fit <- train(training_x,training_y,N[i])

  pred_testing <- test(fit, testing_x)

  error_testing[i] <- mean(pred_testing != as.factor(testing_y))
  cat("Accurate rate for Training Random Forest with " ,N[i]," trees is ", 1-error_testing[i] )

}

pdf("../output/Choose the best parameter of RF.pdf",height=8,width=8)
plot(N,c(0.7577778,0.7622222,0.7633333, 0.7577778,0.7611111,0.7555556,0.7622222),type = "b",xlab="Number of trees used in RF",ylab="Accurate rate",main="Choose the best parameter")
dev.off()

```

##### We can see the best parameter should be 500.

Elapsed time for Training Random Forest with 300 trees is  391.618  seconds 
Accurate rate for Training Random Forest with  300  trees is  0.7577778

Elapsed time for Training Random Forest with 400 trees is  513.531  seconds 
Accurate rate for Training Random Forest with  400  trees is  0.7622222

Elapsed time for Training Random Forest with 500 trees is  645.839  seconds 
Accurate rate for Training Random Forest with  500  trees is  0.7633333

Elapsed time for Training Random Forest with 500 trees is  774.347  seconds 
Accurate rate for Training Random Forest with  600  trees is  0.7577778

Elapsed time for Training Random Forest with 700 trees is  908.717  seconds 
Accurate rate for Training Random Forest with  700  trees is  0.7611111

Elapsed time for Training Random Forest with 800 trees is  1032.084  seconds 
Accurate rate for Training Random Forest with  800  trees is  0.7555556

Elapsed time for Training Random Forest with  900  trees is  1377.687  seconds 
Accurate rate for Training Random Forest with  900  trees is  0.7622222


### Step4: Cross Validation Function 

```{r}

cv.function <- function(data, label, K){
  # data: the whole dataset
  # label: a column vector with 0 and 1
  # K: number of folds during the cross validation process

  set.seed(2249)
  library(caret)

  fold <- createFolds(1:nrow(data), K, list=T, returnTrain=F)
  fold <- as.data.frame(fold)
  
  cv.error <- c()
  
  for (i in 1:K){
    
    test.data <- data[fold[,i],]
    train.data <- data[-fold[,i],]
    test.label <- label[fold[,i],]
    train.label <- label[-fold[,i],]
    
    fit <- train(train.data, train.label,N=500)
    pred <- test(fit, test.data)  
    cv.error[i] <- mean(pred != test.label)
  }
  
   return(mean(cv.error))
}


```

### Feature selection

##### 1. full SIFT

```{r}
sift_train<- read.csv("../data/training_set/sift_train.csv")
label_train<- read.csv("../data/training_set/label_train.csv")
training_y<- matrix(label_train[, 2],ncol=1)
colnames(training_y)<-"y"
training_x<- sift_train[, -1]

cv.sift.rf<-cv.function(training_x,training_y,K=5)

ar_cv.sift.rf<- 1-0.2256667
#0.7743333

(878.609+889.932+1028.253+1009.64+974.066)/60/5
#average time 3.39922 min
```

##### 2.HOG

```{r}
HOG_train <- rbind(read.csv("../output/hog_training.csv"),read.csv("../output/hog_testing.csv"))

training_y<- matrix(HOG_train[,ncol(HOG_train)],ncol=1)
colnames(training_y)<-"y"
training_x<- HOG_train [, -ncol(HOG_train)]

cv.HOG.rf<-cv.function(training_x,training_y,K=5)

ar_cv.HOG.rf<-1-cv.HOG.rf
# 0.7986667

(207.692+217.175+214.046+183.102+197.751)/60/5
#average time 3.39922 min
```


##### 3.RGB

```{r}
RGB_train<- read.csv("../output/rgb_feature.csv")

training_y<- matrix(RGB_train[,ncol(RGB_train)],ncol=1)
colnames(training_y)<-"y"
training_x<- RGB_train[, -ncol(RGB_train)]

cv.RGB.rf<-cv.function(training_x,training_y,K=5)

ar_cv.RGB.rf0<-1-0.143
#0.857

(164.873+170.481+164.421+169.656+192.173)/60/5
#average time 2.872013 min
```

```{r}
RGB_train<- read.csv("../output/rgb_feature1.csv")

training_y<- matrix(RGB_train[,ncol(RGB_train)],ncol=1)
colnames(training_y)<-"y"
training_x<- RGB_train[, -ncol(RGB_train)]

cv.RGB.rf<-cv.function(training_x,training_y,K=5)

ar_cv.RGB.rf1<-1-0.141
#0.859

(269.886+245.697+243.979+251.042+251.89)/60/5
#average time 4.208313 min
```

```{r}
RGB_train<- read.csv("../output/rgb_feature2.csv")

training_y<- matrix(RGB_train[,ncol(RGB_train)],ncol=1)
colnames(training_y)<-"y"
training_x<- RGB_train[, -ncol(RGB_train)]

cv.RGB.rf<-cv.function(training_x,training_y,K=5)
ar_cv.RGB.rf2 <- 1 - 0.1446667
#0.8553333

 (144.125+ 147.693+131.578+ 134.05+138.026)/60/5
#average time 2.31824 min
```


##### 3.HSV

```{r}
HSV_train<- read.csv("../output/hsv_feature.csv")

training_y<- matrix(HSV_train[,ncol(HSV_train)],ncol=1)
colnames(training_y)<-"y"
training_x<- HSV_train[, -ncol(HSV_train)]


cv.HSV.rf<-cv.function(training_x,training_y,K=5)
ar_cv.HSV.rf<-1-cv.HSV.rf
# 0.843

( 92.745 +102.637+96.04+91.84+88.099)/60/5
#average time 1.571203 min
```




